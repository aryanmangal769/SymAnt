<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SymAnt: Action Anticipation with Symbolic Knowledge Diffusion</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        .header {
            text-align: center;
            border-bottom: 2px solid #eee;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }
        .section {
            margin-bottom: 40px;
        }
        .figure {
            text-align: center;
            margin: 20px 0;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: center;
        }
        .code-link {
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>SymAnt: Action Anticipation with Symbolic Knowledge Diffusion</h1>
        <p>Anonymous ICCV 2025 Submission #14909</p>
    </div>

    <div class="section">
        <h2>Abstract</h2>
        <p>As robots and intelligent systems increasingly interact with humans, the ability to understand users by anticipating their actions becomes significantly important. We introduce a novel neuro-symbolic approach that unifies neural networks with symbolic knowledge through scene and knowledge graphs to effectively anticipate actions from short videos. Our method reduces model size and contextual observation requirements while achieving state-of-the-art performance across four datasets (Breakfast, 50 Salads, EPIC Kitchens, and EGTEA Gaze+), outperforming existing methods by up to 5%.</p>
    </div>

    <div class="section">
        <h2>Method Overview</h2>
        <div class="figure">
            <img src="figure1.png" alt="Method architecture" style="max-width: 800px;">
            <p>Figure 1: Our neuro-symbolic framework combining scene graphs (green) and knowledge graphs (blue/purple) with a diffusion-inspired decoder.</p>
        </div>
        <ul>
            <li>Joint graph search over spatial relationships and object affordances</li>
            <li>Diffusion-inspired iterative action refinement</li>
            <li>Mamba-based video encoder for efficient processing</li>
        </ul>
    </div>

    <div class="section">
        <h2>Results</h2>
        <h3>Performance Comparison (MoC Score)</h3>
        <table>
            <tr>
                <th>Dataset</th>
                <th>Breakfast</th>
                <th>50 Salads</th>
                <th>EPIC Kitchens</th>
            </tr>
            <tr>
                <td>SymAnt (Ours)</td>
                <td>27.55</td>
                <td>35.08</td>
                <td>42.47</td>
            </tr>
            <tr>
                <td>Previous SOTA</td>
                <td>24.59</td>
                <td>34.00</td>
                <td>39.10</td>
            </tr>
        </table>
    </div>

    <div class="section">
        <h2>Code & Resources</h2>
        <div class="code-link">
            <a href="https://anonymous.4open.science/r/SymAnt-792E" target="_blank">View Code Repository</a>
        </div>
    </div>

    <div class="section">
        <h2>Citation</h2>
        <pre>
@article{symant2025,
    title={SymAnt: Action Anticipation with Symbolic Knowledge Diffusion},
    author={Anonymous},
    journal={ICCV},
    year={2025}
}</pre>
    </div>
</body>
</html>
